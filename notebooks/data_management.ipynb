{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Some standard import statements that are nice for Jupyter\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "\n",
    "import time\n",
    "\n",
    "import json\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, stream=sys.stdout)\n",
    "\n",
    "# importing my model functions for analysis\n",
    "from psi_transmission.model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organization of the data files\n",
    "\n",
    "In a new directory, at data_main/sorted, I have copied only the good run files (with this determination precipitating from the work in the parsing_elog notebooks). I have renamed every .tof and every .txt file according to the following convention: inheritedFileName_configuration_runtype.tof(txt). Here are my conventions for configuration and runtype:\n",
    "\n",
    "- NORM - normalization\n",
    "- JPTI - JP Ti guide with NiP\n",
    "- JPSU - JP SUS guide with NiP\n",
    "- DISK - SS Disk\n",
    "- GD01 - UGD01 guide\n",
    "- GD03 - UGD03 guide\n",
    "- EPSU - EP SUS guide with NiP\n",
    "\n",
    "\n",
    "- s005 - 5 second storage measurement\n",
    "- s020 - 20 second storage measurement\n",
    "- s100 - 100 second storage measurement\n",
    "- shot - direct shot measurement\n",
    "\n",
    "For example:\n",
    "\n",
    "T101217_0222_EPSU_s100.tof\n",
    "\n",
    "T091217_0130_NORM_s100.txt\n",
    "\n",
    "### Master Run List:\n",
    "\n",
    "Run #'s                      | Day |  Storage Time (s)   | Configuration          |\n",
    "---                          | --- |      ---            | ---                    |\n",
    "--- - 21                     | 8   |      n/a            | BAD                    |\n",
    " 22 - 24                     | 8   |       20            | normalization          |\n",
    " 25 - 31                     | 8   |      100            | normalization          |\n",
    " 32 - 35*                    | 8   |        5            | normalization          |\n",
    "      48                     | 8   |   direct            | JP SUS guide with NiP  |\n",
    "      49                     | 8   |   direct            | BAD                    |\n",
    " 50 - 60                     | 8   |      100            | JP SUS guide with NiP  |\n",
    " 61 - 63                     | 8   |        5            | JP SUS guide with NiP  |\n",
    " 64 - 66*                    | 8   |       20            | JP SUS guide with NiP  |\n",
    "      76                     | 8   |   direct            | normalization          |\n",
    " 77 - 79                     | 8   |        5            | normalization          |\n",
    " 80 - 82                     | 8   |       20            | normalization          |\n",
    " 83 - 88$^\\dagger$           | 8   |      100            | normalization          |\n",
    "      98                     | 8   |   direct            | JP Ti guide with NiP   |\n",
    " 99 - 105                    | 8   |      100            | JP Ti guide with NiP   |\n",
    "  1 - 90                     | 9   |      100            | JP Ti guide with NiP   |\n",
    " 99 - 101                    | 9   |       20            | JP Ti guide with NiP   |\n",
    "102 - 110                    | 9   |        5            | JP Ti guide with NiP   |\n",
    "      120                    | 9   |   direct            | normalization          |\n",
    "121 - 123                    | 9   |        5            | normalization          |\n",
    "124 - 125                    | 9   |       20            | normalization          |\n",
    "      126                    | 9   |       20            | BAD                    |\n",
    "      127                    | 9   |       20            | normalization          |\n",
    "128 - 135                    | 9   |      100            | normalization          |\n",
    "      145                    | 9   |   direct            | SS disk                |\n",
    "146 - 153                    | 9   |      100            | SS disk                |\n",
    "154 - 156                    | 9   |       20            | SS disk                |\n",
    "157 - 159                    | 9   |        5            | SS disk                |\n",
    "      175                    | 9   |   direct            | normalization          |\n",
    "176 - 183                    | 9   |      100            | normalization          |\n",
    "184 - 186                    | 9   |       20            | normalization          |\n",
    "187 - 189                    | 9   |        5            | normalization          |\n",
    "      198                    | 9   |   direct            | UGD01                  |\n",
    "      199                    | 9   |      100            | UGD01                  |\n",
    "  1 - 107                    | 10  |      100            | UGD01                  |\n",
    "108 - 110                    | 10  |       20            | UGD01                  |\n",
    "111 - 113                    | 10  |        5            | UGD01                  |\n",
    "      122                    | 10  |   direct            | normalization          |\n",
    "123 - 130                    | 10  |      100            | normalization          |\n",
    "131 - 133                    | 10  |       20            | normalization          |\n",
    "134 - 136                    | 10  |        5            | normalization          |\n",
    "      145                    | 10  |   direct            | UGD03                  |\n",
    "146 - 155                    | 10  |      100            | UGD03                  |\n",
    "156 - 158                    | 10  |       20            | UGD03                  |\n",
    "159 - 161                    | 10  |        5            | UGD03                  |\n",
    "      170                    | 10  |   direct            | normalization          |\n",
    "171 - 179                    | 10  |      100            | normalization          |\n",
    "180 - 182                    | 10  |       20            | normalization          |\n",
    "183 - 185                    | 10  |        5            | normalization          |\n",
    "193 - 194                    | 10  |   direct            | EP SUS guide with NiP  |\n",
    "      195                    | 10  |      100            | EP SUS guide with NiP  |\n",
    "196 - 198                    | 10  |        5            | EP SUS guide with NiP  |\n",
    "199 - 201                    | 10  |       20            | EP SUS guide with NiP  |\n",
    "202 - 241                    | 10  |      100            | EP SUS guide with NiP  |\n",
    "      249                    | 10  |   direct            | normalization          |\n",
    "250 - 252                    | 10  |        5            | normalization          |\n",
    "253 - 255                    | 10  |       20            | normalization          |\n",
    "256 - 265$^{**}$             | 10  |      100            | normalization          |\n",
    "273 - 274$^{\\dagger\\dagger}$ | 10  |   direct            | bad?                   |\n",
    "275 - 278                    | 10  |       20            | bad?                   |\n",
    "  1 -  93                    | 11  |       20            | bad?                   |\n",
    "\n",
    "\\* *configuration change, background included* <br/>\n",
    "$^\\dagger$ *to be checked in the data (remove noise at the end)* <br/>\n",
    "\\*\\* *... cleaning the area ...* <br/>\n",
    "$^{\\dagger\\dagger}$ *(we connect both plexi guides together, as at the beginning)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "\n",
    "The function used to load the data should take a few strings that determine what types of runs and configuration we want. The function should just return an array with a row for each run, and the columns:\n",
    "\n",
    "\\[time_since_experiment_start, storage_time, integrated_counts\\]\n",
    "\n",
    "for direct shot measurements we can set the storage time to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \"NORM\"\n",
    "run_type = \"shot\"\n",
    "    \n",
    "# initialize an empty array\n",
    "data = np.empty()\n",
    "\n",
    "# Every file in the directory containing main detector run data is iterated over.\n",
    "# Here the /sorted directory contains just runs deemed good for analysis.\n",
    "for filename in os.listdir('../data_main/sorted'):\n",
    "    \n",
    "    # Only the files matching our desired configuration and run type are selected\n",
    "    if ((config in filename) and (run_type in filename)):\n",
    "        \n",
    "        # The start time of the run is retrieved from the .txt file\n",
    "        if ('.txt' in filename):\n",
    "            \n",
    "            f = open(filename)  \n",
    "            lines = f.readlines()\n",
    "            f.close()\n",
    "            # grab the epoch time for run start\n",
    "            date_time = str(day_list[i]).zfill(2) + '.12.2017 ' + lines[26][15:23]\n",
    "            pattern = '%d.%m.%Y %H:%M:%S'\n",
    "            run_start_time = int(time.mktime(time.strptime(date_time, pattern)))\n",
    "        \n",
    "            # This function returns the start time of the very first run. \n",
    "            run_start_time = get_first_run_time() - run_start_time\n",
    "\n",
    "        # The data is retrieved from the .tof file\n",
    "        if ('.tof' in filename):\n",
    "            \n",
    "            \n",
    "            \n",
    "# iterating through the run list\n",
    "for i in range(0, np.size(run_list)):\n",
    "\n",
    "    if not (just_monitor_flag):\n",
    "\n",
    "        # grab the vectors of UCN counts\n",
    "        data[:,i] = np.loadtxt(\"../data_main/12/\" + str(day_list[i]) + \"/T\"\n",
    "        + str(day_list[i]).zfill(2) + \"1217_\" + str(run_list[i]).zfill(4) + \n",
    "        \".tof\", usecols = (1))\n",
    "\n",
    "    if (normalize_flag):\n",
    "\n",
    "        # normalize the vector according to the start time of the run. Here we\n",
    "        # are normalizing based on the degradation of the UCN source yield over\n",
    "        # time\n",
    "        norm_factor = yield_normalization(run_list[i], day_list[i], \n",
    "        yield_fit_parameters)\n",
    "\n",
    "        data[:,i] * norm_factor\n",
    "\n",
    "    monitor_data[:,i] = np.loadtxt(\"../data_monitor/12/\" + \"T\"\n",
    "    + str(day_list[i]).zfill(2) + \"1217_\" + str(run_list[i]).zfill(4) + \n",
    "    \".tof\", usecols = (1))\n",
    "\n",
    "# get the run times\n",
    "run_times = get_run_times(run_list, day_list, just_monitor_flag)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_bins = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-cf3514c01691>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \"\"\"\n\u001b[1;32m    282\u001b[0m     \u001b[0m_warn_for_nonsequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "vector = np.zeros((3,1))\n",
    "data = np.array([])\n",
    "if (data[0] ):\n",
    "    \n",
    "np.vstack((data, vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
